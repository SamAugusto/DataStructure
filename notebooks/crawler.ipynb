{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "17fb04da",
      "metadata": {
        "id": "17fb04da"
      },
      "source": [
        "# Crawler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "457822ea",
      "metadata": {
        "id": "457822ea"
      },
      "source": [
        "[Click here to run this chapter on Colab](https://colab.research.google.com/github/AllenDowney/DSIRP/blob/main/notebooks/crawler.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5cbc301",
      "metadata": {
        "id": "e5cbc301"
      },
      "source": [
        "## Crawling the web\n",
        "\n",
        "At this point we have all the pieces we need to build a web crawler; it's time to bring them together.\n",
        "\n",
        "First, from `philosophy.ipynb`, we have `WikiFetcher`, which we'll use to download pages from Wikipedia while limiting requests to about one per second."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a9a87a52",
      "metadata": {
        "id": "a9a87a52"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "from time import time, sleep\n",
        "\n",
        "class WikiFetcher:\n",
        "    next_request_time = None\n",
        "    min_interval = 1  # second\n",
        "\n",
        "    def fetch_wikipedia(self, url):\n",
        "        self.sleep_if_needed()\n",
        "        fp = urlopen(url)\n",
        "        soup = BeautifulSoup(fp, 'html.parser')\n",
        "        return soup\n",
        "\n",
        "    def sleep_if_needed(self):\n",
        "        if self.next_request_time:\n",
        "            sleep_time = self.next_request_time - time()\n",
        "            if sleep_time > 0:\n",
        "                sleep(sleep_time)\n",
        "\n",
        "        self.next_request_time = time() + self.min_interval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ebc98c7",
      "metadata": {
        "id": "5ebc98c7"
      },
      "source": [
        "Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ca8689bc",
      "metadata": {
        "id": "ca8689bc"
      },
      "outputs": [],
      "source": [
        "fetcher = WikiFetcher()\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/Python_(programming_language)'\n",
        "soup = fetcher.fetch_wikipedia(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4799dd28",
      "metadata": {
        "id": "4799dd28"
      },
      "source": [
        "The result is a BeautifulSoup object that represents the document object model (DOM) of the page.\n",
        "\n",
        "Note that `WikiFetcher` won't work if `url` is a bytearray, because `urlopen` doesn't work with bytearrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f7876a10",
      "metadata": {
        "id": "f7876a10"
      },
      "outputs": [],
      "source": [
        "url = b'https://en.wikipedia.org/wiki/Python_(programming_language)'\n",
        "# soup = fetcher.fetch_wikipedia(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "112bd118",
      "metadata": {
        "id": "112bd118"
      },
      "source": [
        "To convert a bytearray to a string, you have to decode it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "51206d5e",
      "metadata": {
        "id": "51206d5e"
      },
      "outputs": [],
      "source": [
        "url_str = url.decode()\n",
        "soup = fetcher.fetch_wikipedia(url_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "150d2b05",
      "metadata": {
        "id": "150d2b05"
      },
      "source": [
        "Usually when you call `decode`, you should [specify which encoding to use](https://docs.python.org/3.8/library/stdtypes.html#bytes.decode). But in this case we know that the original strings were URLs, so the default encoding will work.\n",
        "\n",
        "Wikipedia pages contain boilerplate content that we don't want to index, so we'll select the `div` element that contains the \"body content\" of the page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "118a5b1e",
      "metadata": {
        "id": "118a5b1e"
      },
      "outputs": [],
      "source": [
        "root = soup.find(class_='mw-body-content')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72873ecb",
      "metadata": {
        "id": "72873ecb"
      },
      "source": [
        "## Finding links\n",
        "\n",
        "From `philosophy.ipynb`, we have the following function that traverses the DOM and finds links."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ec3146d4",
      "metadata": {
        "id": "ec3146d4"
      },
      "outputs": [],
      "source": [
        "from bs4 import Tag\n",
        "\n",
        "def link_generator(root):\n",
        "    for element in root.descendants:\n",
        "        if isinstance(element, Tag) and element.name == 'a':\n",
        "            href = element.get('href', '')\n",
        "            if href.startswith('/wiki'):\n",
        "                yield element"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e63ece98",
      "metadata": {
        "id": "e63ece98"
      },
      "source": [
        "This version includes links to images and other links we probably don't want to index.\n",
        "\n",
        "The following version includes a condition that checks whether the link has a `title` attribute, which seems to select mostly \"good\" links."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "35541f47",
      "metadata": {
        "id": "35541f47"
      },
      "outputs": [],
      "source": [
        "def link_generator(root):\n",
        "    for element in root.descendants:\n",
        "        if isinstance(element, Tag) and element.name == 'a':\n",
        "            title = element.get('title', '')\n",
        "            href = element.get('href', '')\n",
        "            if title and href.startswith('/wiki'):\n",
        "                yield element"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "680a9f82",
      "metadata": {
        "id": "680a9f82"
      },
      "source": [
        "Here are the first few links from the page we downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d50e3acb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d50e3acb",
        "outputId": "b2431c63-9155-4cc3-8e35-89789566f6c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a href=\"/wiki/Programming_paradigm\" title=\"Programming paradigm\">Paradigm</a>\n",
            "<a class=\"mw-redirect\" href=\"/wiki/Multi-paradigm\" title=\"Multi-paradigm\">Multi-paradigm</a>\n",
            "<a href=\"/wiki/Object-oriented_programming\" title=\"Object-oriented programming\">object-oriented</a>\n",
            "<a href=\"/wiki/Procedural_programming\" title=\"Procedural programming\">procedural</a>\n",
            "<a href=\"/wiki/Imperative_programming\" title=\"Imperative programming\">imperative</a>\n",
            "<a href=\"/wiki/Functional_programming\" title=\"Functional programming\">functional</a>\n"
          ]
        }
      ],
      "source": [
        "for i, link in enumerate(link_generator(root)):\n",
        "    print(link)\n",
        "    if i == 5:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3decf3bc",
      "metadata": {
        "id": "3decf3bc"
      },
      "source": [
        "## Finding words\n",
        "\n",
        "From `indexer.ipynb`, we have the following function, which traverses the DOM and yields individual words, stripped of punctuation and converted to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e7b75e21",
      "metadata": {
        "id": "e7b75e21"
      },
      "outputs": [],
      "source": [
        "from bs4 import NavigableString\n",
        "from string import whitespace, punctuation\n",
        "\n",
        "def iterate_words(root):\n",
        "    for element in root.descendants:\n",
        "        if isinstance(element, NavigableString):\n",
        "            for word in element.string.split():\n",
        "                word = word.strip(whitespace + punctuation)\n",
        "                if word:\n",
        "                    yield word.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe0c90b",
      "metadata": {
        "id": "afe0c90b"
      },
      "source": [
        "Here are the first words from the page we downloaded. They include keywords from the sidebar on the right side of the page, which are not part of the main text, but might be good to index anyway, since they indicate the topic of the page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fc352e10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc352e10",
        "outputId": "92a69cab-fddf-43ff-c193-36d5206a9cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "general-purpose\n",
            "programming\n",
            "language\n",
            "mw-parser-output\n",
            "hlist\n",
            "dl,.mw-parser-output\n",
            "hlist\n",
            "ol,.mw-parser-output\n",
            "hlist\n",
            "ul{margin:0;padding:0}.mw-parser-output\n",
            "hlist\n",
            "dd,.mw-parser-output\n",
            "hlist\n",
            "dt,.mw-parser-output\n",
            "hlist\n",
            "li{margin:0;display:inline}.mw-parser-output\n",
            "hlist.inline,.mw-parser-output\n",
            "hlist.inline\n",
            "dl,.mw-parser-output\n",
            "hlist.inline\n",
            "ol,.mw-parser-output\n",
            "hlist.inline\n",
            "ul,.mw-parser-output\n",
            "hlist\n",
            "dl\n",
            "dl,.mw-parser-output\n",
            "hlist\n",
            "dl\n",
            "ol,.mw-parser-output\n",
            "hlist\n",
            "dl\n",
            "ul,.mw-parser-output\n",
            "hlist\n",
            "ol\n",
            "dl,.mw-parser-output\n",
            "hlist\n",
            "ol\n",
            "ol,.mw-parser-output\n",
            "hlist\n",
            "ol\n",
            "ul,.mw-parser-output\n",
            "hlist\n",
            "ul\n",
            "dl,.mw-parser-output\n",
            "hlist\n",
            "ul\n",
            "ol,.mw-parser-output\n",
            "hlist\n",
            "ul\n",
            "ul{display:inline}.mw-parser-output\n",
            "hlist\n",
            "mw-empty-li{display:none}.mw-parser-output\n",
            "hlist\n",
            "dt::after{content\n",
            "mw-parser-output\n",
            "hlist\n",
            "dd::after,.mw-parser-output\n",
            "hlist\n",
            "li::after{content\n",
            "·\n",
            "font-weight:bold}.mw-parser-output\n",
            "hlist\n",
            "dd:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dt:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "li:last-child::after{content:none}.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "dd:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "dt:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "li:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "dd:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "dt:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "li:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "dd:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "dt:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "li:first-child::before{content\n",
            "font-weight:normal}.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "dd:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "dt:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "li:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "dd:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "dt:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "li:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "dd:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "dt:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output\n",
            "hlist\n",
            "ol{counter-reset:listitem}.mw-parser-output\n",
            "hlist\n",
            "ol>li{counter-increment:listitem}.mw-parser-output\n",
            "hlist\n",
            "ol>li::before{content\n",
            "counter(listitem)\"\\a0\n",
            "mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "ol>li:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "ol>li:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "ol>li:first-child::before{content\n",
            "counter(listitem)\"\\a0\n",
            "mw-parser-output\n",
            "infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output\n",
            "infobox-3cols-child{margin:auto}.mw-parser-output\n",
            "infobox\n",
            "navbar{font-size:100%}@media\n",
            "screen{html.skin-theme-clientpref-night\n",
            "mw-parser-output\n",
            "infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media\n",
            "screen\n",
            "and\n",
            "prefers-color-scheme:dark){html.skin-theme-clientpref-os\n",
            "mw-parser-output\n",
            "infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive\n",
            "mw-parser-output\n",
            "infobox-table{display:table!important}body.skin--responsive\n",
            "mw-parser-output\n",
            "infobox-table>caption{display:table-caption!important}body.skin--responsive\n",
            "mw-parser-output\n",
            "infobox-table>tbody{display:table-row-group}body.skin--responsive\n",
            "mw-parser-output\n",
            "infobox-table\n",
            "th,body.skin--responsive\n",
            "mw-parser-output\n",
            "infobox-table\n",
            "td{padding-left:inherit;padding-right:inherit\n",
            "python\n",
            "paradigm\n",
            "multi-paradigm\n",
            "object-oriented\n",
            "1\n",
            "procedural\n",
            "imperative\n",
            "functional\n",
            "structured\n",
            "reflective\n",
            "designed\n",
            "by\n",
            "guido\n",
            "van\n",
            "rossum\n",
            "developer\n",
            "python\n",
            "software\n",
            "foundation\n",
            "first\n",
            "appeared\n",
            "20\n",
            "february\n",
            "1991\n",
            "34\n",
            "years\n",
            "ago\n",
            "1991-02-20\n",
            "2\n",
            "stable\n",
            "release\n",
            "3.13.5\n",
            "3\n",
            "11\n",
            "june\n",
            "2025\n",
            "48\n"
          ]
        }
      ],
      "source": [
        "for i, word in enumerate(iterate_words(root)):\n",
        "    print(word)\n",
        "    if i > 200:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbfd17ff",
      "metadata": {
        "id": "fbfd17ff"
      },
      "source": [
        "## Redis\n",
        "\n",
        "Let's get Redis started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1cbe8a49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cbe8a49",
        "outputId": "6d7e3311-f87c-423f-c13a-1caf549f6268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,160 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,508 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,269 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,255 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,161 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,574 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,775 kB]\n",
            "Fetched 27.1 MB in 3s (8,915 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-tools\n",
            "Suggested packages:\n",
            "  ruby-redis\n",
            "The following NEW packages will be installed:\n",
            "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-server\n",
            "  redis-tools\n",
            "0 upgraded, 7 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 1,273 kB of archives.\n",
            "After this operation, 5,725 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjemalloc2 amd64 5.2.1-4ubuntu1 [240 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblua5.1-0 amd64 5.1.5-8.1build4 [99.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblzf1 amd64 3.6-3 [7,444 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-bitop amd64 1.0.2-5 [6,680 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-cjson amd64 2.1.0+dfsg-2.1 [17.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 redis-tools amd64 5:6.0.16-1ubuntu1 [856 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 redis-server amd64 5:6.0.16-1ubuntu1 [45.9 kB]\n",
            "Fetched 1,273 kB in 0s (3,939 kB/s)\n",
            "Selecting previously unselected package libjemalloc2:amd64.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libjemalloc2_5.2.1-4ubuntu1_amd64.deb ...\n",
            "Unpacking libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
            "Selecting previously unselected package liblua5.1-0:amd64.\n",
            "Preparing to unpack .../1-liblua5.1-0_5.1.5-8.1build4_amd64.deb ...\n",
            "Unpacking liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
            "Selecting previously unselected package liblzf1:amd64.\n",
            "Preparing to unpack .../2-liblzf1_3.6-3_amd64.deb ...\n",
            "Unpacking liblzf1:amd64 (3.6-3) ...\n",
            "Selecting previously unselected package lua-bitop:amd64.\n",
            "Preparing to unpack .../3-lua-bitop_1.0.2-5_amd64.deb ...\n",
            "Unpacking lua-bitop:amd64 (1.0.2-5) ...\n",
            "Selecting previously unselected package lua-cjson:amd64.\n",
            "Preparing to unpack .../4-lua-cjson_2.1.0+dfsg-2.1_amd64.deb ...\n",
            "Unpacking lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
            "Selecting previously unselected package redis-tools.\n",
            "Preparing to unpack .../5-redis-tools_5%3a6.0.16-1ubuntu1_amd64.deb ...\n",
            "Unpacking redis-tools (5:6.0.16-1ubuntu1) ...\n",
            "Selecting previously unselected package redis-server.\n",
            "Preparing to unpack .../6-redis-server_5%3a6.0.16-1ubuntu1_amd64.deb ...\n",
            "Unpacking redis-server (5:6.0.16-1ubuntu1) ...\n",
            "Setting up libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
            "Setting up lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
            "Setting up liblzf1:amd64 (3.6-3) ...\n",
            "Setting up lua-bitop:amd64 (1.0.2-5) ...\n",
            "Setting up liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
            "Setting up redis-tools (5:6.0.16-1ubuntu1) ...\n",
            "Setting up redis-server (5:6.0.16-1ubuntu1) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/redis.service → /lib/systemd/system/redis-server.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/redis-server.service → /lib/systemd/system/redis-server.service.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Install redis-server\n",
        "    !apt-get update\n",
        "    !apt-get install redis-server\n",
        "    # Start redis-server\n",
        "    !redis-server --daemonize yes\n",
        "else:\n",
        "    !redis-server --daemonize yes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa23066c",
      "metadata": {
        "id": "aa23066c"
      },
      "source": [
        "And make sure the Redis client is installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "68fecf23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68fecf23",
        "outputId": "7a81d7f6-9839-49ab-b7c6-299806ae1b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting redis\n",
            "  Downloading redis-6.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading redis-6.2.0-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.7/278.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: redis\n",
            "Successfully installed redis-6.2.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import redis\n",
        "except ImportError:\n",
        "    !pip install redis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99acc3db",
      "metadata": {
        "id": "99acc3db"
      },
      "source": [
        "We'll make a `Redis` object that creates the connection to the Redis database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5e35a4cd",
      "metadata": {
        "id": "5e35a4cd"
      },
      "outputs": [],
      "source": [
        "import redis\n",
        "\n",
        "r = redis.Redis()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74cd2e6d",
      "metadata": {
        "id": "74cd2e6d"
      },
      "source": [
        "If you have a Redis database running on a different machine, you can create a `Redis` object using the URL of the database, like this\n",
        "\n",
        "```\n",
        "url = 'redis://redistogo:example@dory.redistogo.com:10534/'\n",
        "r = redis.Redis.from_url(url)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12d92512",
      "metadata": {
        "id": "12d92512"
      },
      "source": [
        "If your database contains values from previous exercises, or if you make a mistake and want to start over, you can use the following function to clear the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8e2889b7",
      "metadata": {
        "id": "8e2889b7"
      },
      "outputs": [],
      "source": [
        "def clear_redis(r):\n",
        "    for key in r.keys():\n",
        "        r.delete(key)\n",
        "\n",
        "# clear_redis(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4819b593",
      "metadata": {
        "id": "4819b593"
      },
      "source": [
        "## Indexing\n",
        "\n",
        "From `indexer.ipynb`, here's the function that counts the words on a page and adds the results to a Redis hash.\n",
        "\n",
        "For each word, it creates or updates a hash in the database that maps from URLs to word counts. For example if the word `python` appears 428 times on a page, we could find the hash with key `Index:python` and add an entry that maps from the URL to the number 428."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cae0f2ea",
      "metadata": {
        "id": "cae0f2ea"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "\n",
        "def redis_index(root, url):\n",
        "    counter = Counter(iterate_words(root))\n",
        "    for word, count in counter.items():\n",
        "        if count >= 3:\n",
        "            key = f'Index:{word}'\n",
        "            # print(key, count)\n",
        "            r.hset(key, url, count)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05478a4f",
      "metadata": {
        "id": "05478a4f"
      },
      "source": [
        "The previous version is likely to be slow because it makes many small requests to the database.\n",
        "We can speed it up using a pipeline object, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7f5f3919",
      "metadata": {
        "tags": [],
        "id": "7f5f3919"
      },
      "outputs": [],
      "source": [
        "def redis_index_pipeline(root, url):\n",
        "    counter = Counter(iterate_words(root))\n",
        "    p = r.pipeline(transaction=False)\n",
        "    for word, count in counter.items():\n",
        "        if count >= 3:\n",
        "            key = f'Index:{word}'\n",
        "            # print(key, count)\n",
        "            p.hset(key, url, count)\n",
        "    p.execute()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ddb5a5a",
      "metadata": {
        "id": "0ddb5a5a"
      },
      "source": [
        "Let's see which version is faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4e09700f",
      "metadata": {
        "id": "4e09700f"
      },
      "outputs": [],
      "source": [
        "url = 'https://en.wikipedia.org/wiki/Python_(programming_language)'\n",
        "soup = fetcher.fetch_wikipedia(url)\n",
        "root = soup.find(class_='mw-body-content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a8c478d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8c478d2",
        "outputId": "5408c77d-1081-430d-8d90-33e216a34ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 78.8 ms, sys: 7.53 ms, total: 86.3 ms\n",
            "Wall time: 111 ms\n"
          ]
        }
      ],
      "source": [
        "%time redis_index(root, url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "36dc8ba4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36dc8ba4",
        "outputId": "ad210600-d6c1-4101-d3b1-adce4d17d73a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 24.9 ms, sys: 0 ns, total: 24.9 ms\n",
            "Wall time: 25.2 ms\n"
          ]
        }
      ],
      "source": [
        "%time redis_index_pipeline(root, url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf6bb330",
      "metadata": {
        "id": "cf6bb330"
      },
      "source": [
        "We can use `hscan_iter` to iterate the field-values pairs in the index for the word `python`, and print the URLs of the pages where this word appears and the number of times it appears on each page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f160da90",
      "metadata": {
        "id": "f160da90"
      },
      "outputs": [],
      "source": [
        "key = f'Index:python'\n",
        "\n",
        "for page, count in r.hscan_iter(key):\n",
        "    print(page, count)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "969b9a52",
      "metadata": {
        "id": "969b9a52"
      },
      "source": [
        "Notice that when we get the number back, it's a bytearray. If we want to work with it as a number, we have to convert back to int."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d33be5a",
      "metadata": {
        "id": "4d33be5a"
      },
      "source": [
        "## Crawling\n",
        "\n",
        "In `philosophy.ipynb` we wrote a simple crawler that always follows the first link."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f89bb928",
      "metadata": {
        "id": "f89bb928"
      },
      "outputs": [],
      "source": [
        "from urllib.parse import urljoin\n",
        "\n",
        "target = 'https://en.wikipedia.org/wiki/Philosophy'\n",
        "\n",
        "def get_to_philosophy(url):\n",
        "    visited = []\n",
        "\n",
        "    for i in range(20):\n",
        "        if url == target:\n",
        "            print(f'Got there in {i} steps!')\n",
        "            return visited\n",
        "\n",
        "        if url in visited:\n",
        "            raise ValueError(f'URL already visited {url}')\n",
        "        else:\n",
        "            print(url)\n",
        "            visited.append(url)\n",
        "\n",
        "        soup = fetcher.fetch_wikipedia(url)\n",
        "        root = soup.find(class_='mw-body-content')\n",
        "        link = next(link_generator(root))\n",
        "        url = urljoin(url, link['href'])\n",
        "\n",
        "    return visited"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "15984fde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "15984fde",
        "outputId": "646ba1d1-87fb-4fb8-b06f-1c8cdfd2cd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://en.wikipedia.org/wiki/Python_(programming_language)\n",
            "https://en.wikipedia.org/wiki/Programming_paradigm\n",
            "https://en.wikipedia.org/wiki/Programming_model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "URL already visited https://en.wikipedia.org/wiki/Programming_paradigm",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-32-1601292495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_to_philosophy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-31-1250407340.py\u001b[0m in \u001b[0;36mget_to_philosophy\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'URL already visited {url}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: URL already visited https://en.wikipedia.org/wiki/Programming_paradigm"
          ]
        }
      ],
      "source": [
        "get_to_philosophy(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ab7dff8",
      "metadata": {
        "id": "7ab7dff8"
      },
      "source": [
        "Now we want a crawler that runs a breadth-first search.\n",
        "Here's the implementation of BFS from `bfs.ipynb`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f09fa05c",
      "metadata": {
        "id": "f09fa05c"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "\n",
        "def reachable_nodes_bfs(G, start):\n",
        "    seen = set()\n",
        "    queue = deque([start])\n",
        "    while queue:\n",
        "        node = queue.popleft()\n",
        "        if node not in seen:\n",
        "            seen.add(node)\n",
        "            neighbors = set(G[node]) - seen\n",
        "            queue.extend(neighbors)\n",
        "    return seen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76fc922f",
      "metadata": {
        "id": "76fc922f"
      },
      "source": [
        "\n",
        "**Exercise:** Write a function called `crawl` that takes a starting URL as a parameter, and an optional number of pages to crawl.\n",
        "\n",
        "It should create a queue of URLs and work it's way through the queue, indexing pages as it goes and adding new links to the queue.\n",
        "\n",
        "For a first draft, I suggest using Python data structures to keep track of the queue and the set of URLs that have already been seen/indexed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def link_generator(root):\n",
        "    for element in root.descendants:\n",
        "        if isinstance(element, Tag) and element.name == 'a':\n",
        "            title = element.get('title', '')\n",
        "            href = element.get('href', '')\n",
        "            if title and href.startswith('/wiki'):\n",
        "                yield 'https://en.wikipedia.org' + href"
      ],
      "metadata": {
        "id": "jaK1V0y3XmDi"
      },
      "id": "jaK1V0y3XmDi",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "73501f42",
      "metadata": {
        "id": "73501f42"
      },
      "outputs": [],
      "source": [
        "def crawl(url_string,pages = 50):\n",
        "  seen = set()\n",
        "  queue = deque([url_string])\n",
        "  count = 0\n",
        "\n",
        "  while queue and (pages == 0 or count < pages):\n",
        "    node = queue.popleft()\n",
        "    if node not in seen:\n",
        "      seen.add(node)\n",
        "      soup = fetcher.fetch_wikipedia(node)\n",
        "      root = soup.find(class_='mw-body-content')\n",
        "      links =  link_generator(root)\n",
        "      neighbors = set(links) - seen\n",
        "      queue.extend(neighbors)\n",
        "      count +=1\n",
        "  return seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "1a291c9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a291c9b",
        "outputId": "01519682-7dcf-4117-a827-4821c008cc75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'https://en.wikipedia.org/wiki/API',\n",
              " 'https://en.wikipedia.org/wiki/Abaqus',\n",
              " 'https://en.wikipedia.org/wiki/Astropy',\n",
              " 'https://en.wikipedia.org/wiki/Automatic_differentiation',\n",
              " 'https://en.wikipedia.org/wiki/Baidu',\n",
              " 'https://en.wikipedia.org/wiki/Beta_release',\n",
              " 'https://en.wikipedia.org/wiki/C_(programming_language)',\n",
              " 'https://en.wikipedia.org/wiki/Call_stack',\n",
              " 'https://en.wikipedia.org/wiki/CoffeeScript',\n",
              " 'https://en.wikipedia.org/wiki/Comparison_of_open-source_configuration_management_software',\n",
              " 'https://en.wikipedia.org/wiki/Compiler',\n",
              " 'https://en.wikipedia.org/wiki/Computational_learning_theory',\n",
              " 'https://en.wikipedia.org/wiki/Concatenated',\n",
              " 'https://en.wikipedia.org/wiki/CubicWeb',\n",
              " 'https://en.wikipedia.org/wiki/Data_mapper_pattern',\n",
              " 'https://en.wikipedia.org/wiki/Euler_Mathematical_Toolbox',\n",
              " 'https://en.wikipedia.org/wiki/Here_document',\n",
              " 'https://en.wikipedia.org/wiki/History_of_Python',\n",
              " 'https://en.wikipedia.org/wiki/ISBN_(identifier)',\n",
              " 'https://en.wikipedia.org/wiki/Imperative_programming',\n",
              " 'https://en.wikipedia.org/wiki/LLVM',\n",
              " 'https://en.wikipedia.org/wiki/LabVIEW',\n",
              " 'https://en.wikipedia.org/wiki/MWorks',\n",
              " 'https://en.wikipedia.org/wiki/Matplotlib',\n",
              " 'https://en.wikipedia.org/wiki/Musical_notation',\n",
              " 'https://en.wikipedia.org/wiki/Ninja-IDE',\n",
              " 'https://en.wikipedia.org/wiki/Nuitka',\n",
              " 'https://en.wikipedia.org/wiki/Object_(computer_science)',\n",
              " 'https://en.wikipedia.org/wiki/Operating_system',\n",
              " 'https://en.wikipedia.org/wiki/Programming_language',\n",
              " 'https://en.wikipedia.org/wiki/Psyco',\n",
              " 'https://en.wikipedia.org/wiki/Python_(programming_language)',\n",
              " 'https://en.wikipedia.org/wiki/Red_Hat_Linux',\n",
              " 'https://en.wikipedia.org/wiki/Regular_expression',\n",
              " 'https://en.wikipedia.org/wiki/Ring_(programming_language)',\n",
              " 'https://en.wikipedia.org/wiki/Rust_(programming_language)',\n",
              " 'https://en.wikipedia.org/wiki/SPSS',\n",
              " 'https://en.wikipedia.org/wiki/SYSTAT_(statistics_package)',\n",
              " 'https://en.wikipedia.org/wiki/Scheme_(programming_language)',\n",
              " 'https://en.wikipedia.org/wiki/Scratch_(programming_language)',\n",
              " 'https://en.wikipedia.org/wiki/Simula',\n",
              " 'https://en.wikipedia.org/wiki/Special:BookSources/9780672329784',\n",
              " 'https://en.wikipedia.org/wiki/Special:EditPage/Template:FOSS',\n",
              " 'https://en.wikipedia.org/wiki/Special:EditPage/Template:Numerical_analysis_software',\n",
              " 'https://en.wikipedia.org/wiki/Stack_Overflow',\n",
              " 'https://en.wikipedia.org/wiki/Switch_statement',\n",
              " 'https://en.wikipedia.org/wiki/System_administration',\n",
              " 'https://en.wikipedia.org/wiki/This_(computer_programming)',\n",
              " 'https://en.wikipedia.org/wiki/Tivoization',\n",
              " 'https://en.wikipedia.org/wiki/Unary_operation'}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "url = 'https://en.wikipedia.org/wiki/Python_(programming_language)'\n",
        "seen = crawl(url)\n",
        "seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "b168242e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b168242e",
        "outputId": "42aa3592-2691-4c96-8164-5e0ed41a02bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'https://en.wikipedia.org/wiki/Python_(programming_language)' b'642'\n"
          ]
        }
      ],
      "source": [
        "key = 'Index:the'\n",
        "for page, count in r.hscan_iter(key):\n",
        "    print(page, count)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c4c75d",
      "metadata": {
        "id": "e7c4c75d"
      },
      "source": [
        "For a second draft, consider storing these structures in Redis so they are persistent; that way, you can call `crawl` later and it will pick up from where it left off. Or you could have multiple crawlers running at the same time.\n",
        "\n",
        "Hint: When you read a URL from Redis, you might have to decode it to make a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "386785ec",
      "metadata": {
        "id": "386785ec"
      },
      "outputs": [],
      "source": [
        "queue_key = 'Crawler:queue'\n",
        "\n",
        "r.lpop(queue_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "6f26e885",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f26e885",
        "outputId": "68e02cb0-3ed7-44a5-82a6-7091482f4111"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "seen_key = 'Crawler:seen'\n",
        "\n",
        "r.sismember(seen_key, 'anything')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6-oajh8aneX"
      },
      "id": "s6-oajh8aneX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "469b4d1d",
      "metadata": {
        "id": "469b4d1d"
      },
      "outputs": [],
      "source": [
        "def redis_crawl(url_string,pages = 50):\n",
        "  seen = set()\n",
        "  queue = deque([url_string])\n",
        "  count = 0\n",
        "  server = redis.Redis()\n",
        "\n",
        "  while queue and (pages == 0 or count < pages):\n",
        "    node = queue.popleft()\n",
        "    if node not in seen and not server.sismember(\"SeenLinks\", node):\n",
        "      seen.add(node)\n",
        "      soup = fetcher.fetch_wikipedia(node)\n",
        "      root = soup.find(class_='mw-body-content')\n",
        "      links =  link_generator(root)\n",
        "      neighbors = set(links) - seen\n",
        "      server.sadd(\"SeenLinks\", node)\n",
        "      queue.extend(neighbors)\n",
        "      count +=1\n",
        "  else:\n",
        "      server.delete(\"QueueLinks\")  # Clear any old data\n",
        "      for item in queue:\n",
        "          server.rpush(\"QueueLinks\", item)\n",
        "\n",
        "  return seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "8405926a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8405926a",
        "outputId": "3bc0d76e-6db2-4daa-9e0d-bcb99f1a9ba6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "url = 'https://en.wikipedia.org/wiki/Object-oriented_programming'\n",
        "redis_crawl(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "6eb7e394",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eb7e394",
        "outputId": "3baad8b0-d233-47c6-bd56-851010b61eab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{b'https://en.wikipedia.org/wiki/API',\n",
              " b'https://en.wikipedia.org/wiki/Boston',\n",
              " b'https://en.wikipedia.org/wiki/Byte_Magazine',\n",
              " b'https://en.wikipedia.org/wiki/Cohesion_(computer_science)',\n",
              " b'https://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture',\n",
              " b'https://en.wikipedia.org/wiki/Compiled_language',\n",
              " b'https://en.wikipedia.org/wiki/Data_modeling',\n",
              " b'https://en.wikipedia.org/wiki/Don%27t_repeat_yourself',\n",
              " b'https://en.wikipedia.org/wiki/Duplicate_code',\n",
              " b'https://en.wikipedia.org/wiki/ETH_Z%C3%BCrich',\n",
              " b'https://en.wikipedia.org/wiki/Formal_methods',\n",
              " b'https://en.wikipedia.org/wiki/Functional_specification',\n",
              " b'https://en.wikipedia.org/wiki/Graph_rewriting',\n",
              " b'https://en.wikipedia.org/wiki/IEEE_Annals_of_the_History_of_Computing',\n",
              " b'https://en.wikipedia.org/wiki/IEEE_Computer',\n",
              " b'https://en.wikipedia.org/wiki/ISBN_(identifier)',\n",
              " b'https://en.wikipedia.org/wiki/Imperative_programming',\n",
              " b'https://en.wikipedia.org/wiki/Incremental_build_model',\n",
              " b'https://en.wikipedia.org/wiki/Liskov_substitution_principle',\n",
              " b'https://en.wikipedia.org/wiki/MIT',\n",
              " b'https://en.wikipedia.org/wiki/Macro_(computer_science)',\n",
              " b'https://en.wikipedia.org/wiki/Memento_pattern',\n",
              " b'https://en.wikipedia.org/wiki/Mixins',\n",
              " b'https://en.wikipedia.org/wiki/Monolithic_application',\n",
              " b'https://en.wikipedia.org/wiki/Mutable',\n",
              " b'https://en.wikipedia.org/wiki/Oberon_(programming_language)',\n",
              " b'https://en.wikipedia.org/wiki/Object-oriented_programming',\n",
              " b'https://en.wikipedia.org/wiki/Object_(computer_science)',\n",
              " b'https://en.wikipedia.org/wiki/Object_modeling_language',\n",
              " b'https://en.wikipedia.org/wiki/Parallel_computing',\n",
              " b'https://en.wikipedia.org/wiki/Polymorphism_(computer_science)',\n",
              " b'https://en.wikipedia.org/wiki/Processor_design',\n",
              " b'https://en.wikipedia.org/wiki/Programming_in_the_large_and_programming_in_the_small',\n",
              " b'https://en.wikipedia.org/wiki/Programming_language',\n",
              " b'https://en.wikipedia.org/wiki/REST',\n",
              " b'https://en.wikipedia.org/wiki/Rob_Pike',\n",
              " b'https://en.wikipedia.org/wiki/Role-oriented_programming',\n",
              " b'https://en.wikipedia.org/wiki/SOLID',\n",
              " b'https://en.wikipedia.org/wiki/Simula',\n",
              " b'https://en.wikipedia.org/wiki/Social_software_engineering',\n",
              " b'https://en.wikipedia.org/wiki/Software',\n",
              " b'https://en.wikipedia.org/wiki/Software_deployment',\n",
              " b'https://en.wikipedia.org/wiki/Software_prototyping',\n",
              " b'https://en.wikipedia.org/wiki/Software_quality',\n",
              " b'https://en.wikipedia.org/wiki/Stack-oriented_programming',\n",
              " b'https://en.wikipedia.org/wiki/State_pattern',\n",
              " b'https://en.wikipedia.org/wiki/Systems_engineering',\n",
              " b'https://en.wikipedia.org/wiki/Template:Types_of_programming_languages',\n",
              " b'https://en.wikipedia.org/wiki/This_(computer_programming)',\n",
              " b'https://en.wikipedia.org/wiki/Trait_(computer_programming)'}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "seen_key = \"SeenLinks\"\n",
        "r.smembers(seen_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "a26b4e97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a26b4e97",
        "outputId": "d52c0ee6-66e6-429c-a6b8-4538d93e8eca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2jpukfLrd9oc"
      },
      "id": "2jpukfLrd9oc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "520be26a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "520be26a",
        "outputId": "41877d6a-463b-496b-c37e-fc06f030196e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "unknown url type: 'QueueLinks'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-67-2739665780.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mredis_crawl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"QueueLinks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-61-258373298.py\u001b[0m in \u001b[0;36mredis_crawl\u001b[0;34m(url_string, pages)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msismember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SeenLinks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mseen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_wikipedia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mw-body-content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mlink_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1-871690124.py\u001b[0m in \u001b[0;36mfetch_wikipedia\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch_wikipedia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# accept a URL or a Request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullurl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, url, data, headers, origin_req_host, unverifiable, method)\u001b[0m\n\u001b[1;32m    320\u001b[0m                  \u001b[0morigin_req_host\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munverifiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                  method=None):\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munredirected_hdrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mfull_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeleter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown url type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splithost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: unknown url type: 'QueueLinks'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4cd2bc27",
      "metadata": {
        "id": "4cd2bc27"
      },
      "source": [
        "## Stop words\n",
        "\n",
        "The most common English words are likely to appear on every page.\n",
        "They don't indicate what the page is about, and we might not want to index them. Words that we don't index are sometimes called [stop words](https://en.wikipedia.org/wiki/Stop_word).\n",
        "\n",
        "Once you have indexed a few pages, use the index to identify the words that have appeared the most times, totaled across all pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "0f78d592",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f78d592",
        "outputId": "01c345a9-8809-46df-8c80-7af640795f1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'642']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "word_key = 'Index:the'\n",
        "r.hvals(word_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "91cb30d2",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91cb30d2",
        "outputId": "81daa6ba-9755-487c-a92c-7b6df7345ed3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "642"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "sum(int(x) for x in r.hvals(word_key))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa99d6d",
      "metadata": {
        "tags": [],
        "id": "6fa99d6d"
      },
      "outputs": [],
      "source": [
        "counter = Counter()\n",
        "\n",
        "for word_key in r.keys('Index*'):\n",
        "    total = sum(int(x) for x in r.hvals(word_key))\n",
        "    word = word_key.decode().split(':')[1]\n",
        "    counter[word] = total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f85dd22e",
      "metadata": {
        "tags": [],
        "id": "f85dd22e"
      },
      "outputs": [],
      "source": [
        "counter.most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55fc1ac4",
      "metadata": {
        "id": "55fc1ac4"
      },
      "source": [
        "The following cells use the results to make a Zipf plot, which shows counts versus \"rank\" on a log-log scale (the most common word has rank 1, the next most common has rank 2, and so on).\n",
        "\n",
        "Zipf's law asserts that the distribution of word frequencies follows a power law, which implies that the Zipf plot is approximately a straight line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730225d2",
      "metadata": {
        "id": "730225d2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "res = []\n",
        "\n",
        "for i, (word, count) in enumerate(counter.most_common()):\n",
        "    res.append((i+1, count))\n",
        "\n",
        "rank, count = np.transpose(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4053fe28",
      "metadata": {
        "id": "4053fe28"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(rank, count)\n",
        "plt.xlabel('Rank')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Zipf plot')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "366c1c12",
      "metadata": {
        "id": "366c1c12"
      },
      "source": [
        "## Shutdown\n",
        "\n",
        "If you are running this notebook on your own computer, you can use the following command to shut down the Redis server.\n",
        "\n",
        "If you are running on Colab, it's not really necessary: the Redis server will get shut down when the Colab runtime shuts down (and everything stored in it will disappear)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2b82180",
      "metadata": {
        "id": "a2b82180"
      },
      "outputs": [],
      "source": [
        "!killall redis-server"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77911c35",
      "metadata": {
        "id": "77911c35"
      },
      "source": [
        "*Data Structures and Information Retrieval in Python*\n",
        "\n",
        "Copyright 2021 Allen Downey\n",
        "\n",
        "License: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}